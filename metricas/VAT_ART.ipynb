{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08c869a5"
      },
      "source": [
        "# Modelos ART utilizando a função VAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eefe2b7"
      },
      "source": [
        "## Importando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SIPZQd1aoIDf",
        "outputId": "9b9fa6d9-a80c-4378-a6ef-0fff5da12d5e"
      },
      "outputs": [],
      "source": [
        "!pip install artlib\n",
        "!pip install pyclustertend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "10777266"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import USPS\n",
        "from artlib import FuzzyART, FuzzyARTMAP, FusionART\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, adjusted_rand_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pyclustertend import vat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w4BE74LtjLR"
      },
      "source": [
        "## Aplicando VAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8FUQm6szWRh"
      },
      "source": [
        "O VAT exige um X de 2 dimensões e isso conflita com o modelo ART.\n",
        "\n",
        "Por isso, decidi separar essa parte do código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "iKQJdn-htgZh",
        "outputId": "b45525fc-8eaa-4d6f-bb82-52fdfe977a4f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'datasets' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3990260035.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfull_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
          ]
        }
      ],
      "source": [
        "transform = transforms.ToTensor()\n",
        "full_dataset = datasets.USPS(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "for img, label in full_dataset:\n",
        "    X_list.append(img.numpy().squeeze())  # shape (16,16)\n",
        "    y_list.append(label)\n",
        "\n",
        "X = np.array(X_list)  # (7291, 16, 16)\n",
        "y = np.array(y_list)  # (7291,)\n",
        "print(\"X:\", X.shape, \" y:\", y.shape)\n",
        "\n",
        "# Achatando e normalizando dados\n",
        "# Isso é necessário para o scaler\n",
        "nsamples, h, w = X.shape\n",
        "X_flat = X.reshape((nsamples, h * w))  # (7291, 256)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_flat_scaled = scaler.fit_transform(X_flat)\n",
        "\n",
        "# Dividindo entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_flat_scaled, y, test_size=0.4, random_state=42, stratify=y\n",
        ")\n",
        "print(\"Treino:\", X_train.shape, \"Teste:\", X_test.shape)\n",
        "\n",
        "X_sample = resample(X_train, n_samples=2000, random_state=42)\n",
        "\n",
        "ODM = vat(X_sample, return_odm=True)\n",
        "print(\"Matriz ODM (ordered dissimilarity):\", ODM.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjGNh0Sp3-GK"
      },
      "source": [
        "## Baixando e ordenando dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SA-8QXLzusy",
        "outputId": "d0c55269-5a9d-416e-c42f-213c70730611"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.58M/6.58M [00:00<00:00, 6.63MB/s]\n",
            "100%|██████████| 1.83M/1.83M [00:00<00:00, 2.48MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7291, 16, 16)\n",
            "(7291, 256)\n"
          ]
        }
      ],
      "source": [
        "# Aprendizado não supervisionado\n",
        "train_data = USPS(root='./USPS/', train=True, download=True)\n",
        "test_data = USPS(root='./USPS/', train=False, download=True)\n",
        "\n",
        "X_train = train_data.data\n",
        "y_train = torch.tensor(train_data.targets, dtype=torch.long)\n",
        "\n",
        "X_test = test_data.data\n",
        "y_test = torch.tensor(test_data.targets, dtype=torch.long)\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "# as imagens do conjunto são 16x16\n",
        "n_dim = 16 * 16\n",
        "\n",
        "#flatten images\n",
        "X_train = X_train.reshape(-1, n_dim)\n",
        "X_test = X_test.reshape(-1, n_dim)\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "# Ordenando dados\n",
        "sorted_indices_train = torch.argsort(y_train)\n",
        "X_train_sorted = X_train[sorted_indices_train]\n",
        "y_train_sorted = y_train[sorted_indices_train]\n",
        "\n",
        "sorted_indices_test = torch.argsort(y_test)\n",
        "X_test_sorted = X_test[sorted_indices_test]\n",
        "y_test_sorted = y_test[sorted_indices_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95zlQCtWzrkR"
      },
      "source": [
        "## Fuzzy ART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S19EK7Ee0HyS"
      },
      "source": [
        "Aprendizado não supervionado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GMVVkFOe4FNS"
      },
      "outputs": [],
      "source": [
        "fuzzy_art_model = FuzzyART(rho=0.3, alpha=0.0, beta=1.0)\n",
        "\n",
        "# Estabelecendo bounds\n",
        "lower_bounds = np.zeros(n_dim)\n",
        "upper_bounds = np.full(n_dim, 255.0)\n",
        "\n",
        "fuzzy_art_model.set_data_bounds(lower_bounds, upper_bounds)\n",
        "\n",
        "# Normalização e complement coding\n",
        "train_X_fuzzy_art = fuzzy_art_model.prepare_data(X_train)\n",
        "test_X_fuzzy_art  = fuzzy_art_model.prepare_data(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y-XoBt938oaS"
      },
      "outputs": [],
      "source": [
        "fuzzy_art_model.fit(train_X_fuzzy_art)\n",
        "fuzzy_art_predictions = fuzzy_art_model.predict(test_X_fuzzy_art)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Psw4zP9Bg5",
        "outputId": "68fb91cc-4bb7-4002-dc29-af53cd992e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O ARI do modelo FuzzyART foi:0.04754222620721928\n",
            "O número de clusters foi:284\n"
          ]
        }
      ],
      "source": [
        "ARI = adjusted_rand_score(y_test,fuzzy_art_predictions)\n",
        "print(f'O ARI do modelo FuzzyART foi:{ARI}')\n",
        "num_clusters = fuzzy_art_model.n_clusters\n",
        "print(f\"O número de clusters foi:{num_clusters}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6robUh3qD2AU"
      },
      "source": [
        "## Matriz de acurácia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSuFTcwxF5AT",
        "outputId": "c04b697c-a985-4c95-8cc4-36c53e94c1bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "# Atenção!!!\n",
        "# Para que funcione para outras bases de dados, será necessário ajustar a definição dos limites\n",
        "\n",
        "def train_fuzzyART(X_train_subset, y_train_subset, X_test_subset, y_test_subset):\n",
        "  fuzzy_art_model = FuzzyART(rho=0.3, alpha=0.0, beta=1.0)\n",
        "  fuzzy_art_model.set_data_bounds(lower_bounds, upper_bounds)\n",
        "\n",
        "  train_X_fuzzy_art = fuzzy_art_model.prepare_data(X_train_subset)\n",
        "  test_X_fuzzy_art  = fuzzy_art_model.prepare_data(X_test_subset)\n",
        "\n",
        "  fuzzy_art_model.fit(train_X_fuzzy_art)\n",
        "  fuzzy_art_predictions = fuzzy_art_model.predict(test_X_fuzzy_art)\n",
        "\n",
        "  return adjusted_rand_score(y_test_subset,fuzzy_art_predictions)\n",
        "\n",
        "def generate_acc_matrix_fuzzyART(num_tasks):\n",
        "  train_subsets = []\n",
        "  test_subsets = []\n",
        "\n",
        "  acc_matrix = [[0 for _ in range(num_tasks)] for _ in range(num_tasks)]\n",
        "\n",
        "  for i in range(num_tasks):\n",
        "    for j in range(num_tasks):\n",
        "        # Classes até a i-ésima (inclusive)\n",
        "        train_classes = torch.arange(0, i + 1)\n",
        "\n",
        "        # Máscara de seleção para treino: todas as classes <= i\n",
        "        mask_train = torch.isin(y_train_sorted, train_classes)\n",
        "        X_train_subset = X_train_sorted[mask_train]\n",
        "        y_train_subset = y_train_sorted[mask_train]\n",
        "\n",
        "        # Máscara de seleção para teste: apenas a classe j\n",
        "        mask_test = (y_test_sorted == j)\n",
        "        X_test_subset = X_test_sorted[mask_test]\n",
        "        y_test_subset = y_test_sorted[mask_test]\n",
        "\n",
        "        # Armazena os subconjuntos (opcional)\n",
        "        train_subsets.append((X_train_subset, y_train_subset))\n",
        "        test_subsets.append((X_test_subset, y_test_subset))\n",
        "\n",
        "        # print(f\"Iteração {i}, {j}:\")\n",
        "        # print(f\"  Treino -> classes até {i}, tamanho {len(X_train_subset)}\\n\")\n",
        "        # print(f\"  Treino -> classes até {i}, tamanho {y_train_subset.unique()}\\n\")\n",
        "        # print(f\"  Teste  -> classe {j}, tamanho {len(X_test_subset)}\\n\")\n",
        "        # print(f\"  Teste  -> classe {j}, tamanho {y_test_subset.unique()}\\n\")\n",
        "\n",
        "        acc_matrix[i][j] = train_fuzzyART(\n",
        "                            X_train_subset,\n",
        "                            y_train_subset,  # não é usado na função\n",
        "                            X_test_subset,\n",
        "                            y_test_subset)\n",
        "    return acc_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkF_Ses4ztF9",
        "outputId": "a219c4dd-9fe8-4530-a7c0-2ddc37e16448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "classes = y_train.unique()\n",
        "print(classes)\n",
        "num_tasks = len(classes)\n",
        "\n",
        "# for i in range (1, 6): 1 2 3 4 5\n",
        "\n",
        "def average_accuracy_fuzzyART(num_tasks, acc_matrix):\n",
        "  denominator = num_tasks*(num_tasks+1)/2\n",
        "  acc_sum = 0\n",
        "\n",
        "  for i in range(num_tasks+1):\n",
        "    for j in range(i+1):\n",
        "      acc_sum = acc_sum + acc_matrix[i][j]\n",
        "\n",
        "  return (acc_sum / denominator)\n",
        "\n",
        "def backward_transfer_fuzzyART(num_tasks, acc_matrix):\n",
        "  denominator = num_tasks*(num_tasks-1)/2\n",
        "  acc_sum = 0\n",
        "\n",
        "  for i in range(2, num_tasks+1):\n",
        "    for j in range(i):\n",
        "      acc_sum = acc_sum + (acc_matrix[i][j] - acc_matrix[j][j])\n",
        "\n",
        "  return (acc_sum / denominator)\n",
        "\n",
        "def forward_transfer_fuzzyART(num_tasks, acc_matrix):\n",
        "  denominator = num_tasks*(num_tasks-1)/2\n",
        "  acc_sum = 0\n",
        "  j = 0\n",
        "\n",
        "  for i in range(j-1):\n",
        "    for j in range(num_tasks+1):\n",
        "      acc_sum = acc_sum + acc_matrix[i][j]\n",
        "\n",
        "  return (acc_sum / denominator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3NYKMpe0zpo"
      },
      "source": [
        "## Fuzzy ARTMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1G-Ak1o13w7"
      },
      "outputs": [],
      "source": [
        "fuzzy_artmap_model = FuzzyARTMAP(rho=0.3, alpha=0.0, beta=1.0)\n",
        "\n",
        "# Os limites foram definidos na parte do Fuzzy ART\n",
        "fuzzy_artmap_model.module_a.set_data_bounds(lower_bounds, upper_bounds)\n",
        "\n",
        "# Normalização e complement coding\n",
        "train_X_fuzzy_artmap = fuzzy_artmap_model.prepare_data(X_train)\n",
        "test_X_fuzzy_artmap = fuzzy_artmap_model.prepare_data(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLiAJGJD_qU6"
      },
      "outputs": [],
      "source": [
        "fuzzy_artmap_model.fit(train_X_fuzzy_artmap, y_train)\n",
        "fuzzy_artmap_predictions = fuzzy_artmap_model.predict(test_X_fuzzy_artmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqpTC7po_6Oa"
      },
      "outputs": [],
      "source": [
        "report = classification_report(y_test, fuzzy_artmap_predictions)\n",
        "matrix = confusion_matrix(y_test, fuzzy_artmap_predictions)\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, fuzzy_artmap_predictions)\n",
        "display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "display.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusão - FuzzyARTMAP\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6w4BE74LtjLR",
        "-3NYKMpe0zpo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
